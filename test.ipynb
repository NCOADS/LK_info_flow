{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.linear_causality import LinearLKInformationFlow\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# from causality_subspace import causality_subspace\n",
    "\n",
    "dt=1\n",
    "pn=1\n",
    "T1=[];T2=[]\n",
    "# pca = PCA(n_components=5)  # 假设我们想将数据降到2维  \n",
    "Nt=1000000\n",
    "np.random.seed = 5\n",
    "# for i in tqdm(range(100)):\n",
    "X1=np.random.randn(5,Nt)*0.2\n",
    "X2=np.random.randn(5,Nt)*0.2\n",
    "\n",
    "A1=np.array([[0.9,0.6,0,0.6,0],[0,0.8,0.6,0,0.6],[0,0,0.9,0,0],[0,0,0,0.2,0],[0,0,0,0,0.2]]).T\n",
    "A2=np.array([[0.2,0.6,0,0.6,0],[0,0.2,0.6,0,0.6],[0,0,0.2,0,0],[0,0,0,0.2,0],[0,0,0,0,0.2]]).T\n",
    "\n",
    "B1=-np.array([[0,0,0,0,0],[0,0.,0,0,0],[0,0,0,0.9,0.],[0,0,0,0.,0],[0,0,0,0,0]])\n",
    "B2=-np.array([[0,0,0,0,0],[0,0.0,0,0,0],[0,0,0,0,0],[0,0,0,0.4,0],[0,0,0,0,0]])\n",
    "for it in range(1,Nt):\n",
    "    X1[:,it]=A1@X1[:,it-1]+X1[:,it]+1*B1@X2[:,it-1] \n",
    "    X2[:,it]=A2@X2[:,it-1]+X2[:,it]+1*B2@X1[:,it-1] \n",
    "    \n",
    "XX=np.zeros([10,Nt])\n",
    "XX[:5]=X1\n",
    "XX[5:]=X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = [(2,3),(8,9)]\n",
    "segments = [(0, 5),(5,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkif = LinearLKInformationFlow(np,1)\n",
    "lkif.causality_estimate(XX[:,-15000:].T, lag_list=[1], segments=segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = lkif.get_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True],\n",
       "       [ True,  True]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(result_dict[\"information_flow\"]) > result_dict[\"information_flow_std_origin\"]*2.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True],\n",
       "       [ True,  True]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(result_dict[\"information_flow\"]) > result_dict[\"statistics\"][\"p99_critical_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.00481158e+00, 3.38060437e-03],\n",
       "       [2.47244279e-01, 4.00879888e+00]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(result_dict[\"information_flow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01538825, 0.0014133 ],\n",
       "       [0.00431541, 0.01945412]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict[\"information_flow_std_origin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01538825, 0.00157665],\n",
       "       [0.00631235, 0.01945412]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict[\"information_flow_std\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data/X.dat and Y.dat\n",
    "import pandas as pd\n",
    "data_X = pd.read_csv('data/X.dat', header=None)\n",
    "data_Y = pd.read_csv('data/Y.dat', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = data_X.to_numpy()\n",
    "data_Y = data_Y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((data_X, data_Y), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = [(0,1),(1,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkif = LinearLKInformationFlow(np,1)\n",
    "lkif.causality_estimate(data, lag_list=[1], segments=segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = lkif.get_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 是否存在因果关系 (False 代表无信息流)\n",
      "\n",
      "### 使用原本的方差检验方法\n",
      "```\n",
      "[[ True False]\n",
      " [ True  True]]\n",
      "```\n",
      "### 使用新的方差检验方法\n",
      "```\n",
      "[[ True False]\n",
      " [False  True]]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print('## 是否存在因果关系 (False 代表无信息流)\\n')\n",
    "print(\"### 使用原本的方差检验方法\")\n",
    "print(\"```\")\n",
    "print(np.abs(result_dict[\"information_flow\"]) > result_dict[\"information_flow_std_origin\"] * 1.65)\n",
    "print(\"```\")\n",
    "\n",
    "print(\"### 使用新的方差检验方法\")\n",
    "print(\"```\")\n",
    "print(np.abs(result_dict[\"information_flow\"]) > result_dict[\"information_flow_std\"] * 1.65)\n",
    "print(\"```\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bootstrap\n",
    "from src.linear_causality import LinearLKInformationFlow\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# from causality_subspace import causality_subspace\n",
    "\n",
    "dt=1\n",
    "pn=1\n",
    "T1=[];T2=[]\n",
    "# pca = PCA(n_components=5)  # 假设我们想将数据降到2维  \n",
    "Nt=100000\n",
    "np.random.seed = 5\n",
    "# for i in tqdm(range(100)):\n",
    "X1=np.random.randn(3,Nt)*0.2\n",
    "X2=np.random.randn(3,Nt)*0.2\n",
    "\n",
    "A1=np.array([[0.9,0.6,0,],[0,0.8,0.6,],[0,0,0.9,]]).T\n",
    "A2=np.array([[0.2,0.6,0,],[0,0.2,0.6,],[0,0,0.2]]).T\n",
    "\n",
    "B1=-np.array([[0,0,0],[0,0.,0],[0,0,0]])\n",
    "B2=-np.array([[0,0,0],[0,0.,0],[0,0,0]])\n",
    "for it in range(1,Nt):\n",
    "    X1[:,it]=A1@X1[:,it-1]+X1[:,it]+1*B1@X2[:,it-1] \n",
    "    X2[:,it]=A2@X2[:,it-1]+X2[:,it]+1*B2@X1[:,it-1] \n",
    "    \n",
    "XX=np.zeros([6,Nt])\n",
    "XX[:3]=X1\n",
    "XX[3:]=X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_resample(data, n_resamples=1000):\n",
    "    resamples = []\n",
    "    for _ in range(n_resamples):\n",
    "        resample = data[np.random.choice(data.shape[0], size=data.shape[0], replace=True), :]\n",
    "        resamples.append(resample)\n",
    "    return np.array(resamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mbootstrap_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_resamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m, in \u001b[0;36mbootstrap_resample\u001b[0;34m(data, n_resamples)\u001b[0m\n\u001b[1;32m      4\u001b[0m     resample \u001b[38;5;241m=\u001b[39m data[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], size\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), :]\n\u001b[1;32m      5\u001b[0m     resamples\u001b[38;5;241m.\u001b[39mappend(resample)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresamples\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a = bootstrap_resample(XX.T, n_resamples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = [(0,1),(1,2),(2,3),(3,4),(4,5),(5,6)]\n",
    "lkif = LinearLKInformationFlow(np,1)\n",
    "lkif.causality_estimate(XX[:,-15000:].T, lag_list=[1], segments=segments)\n",
    "result_dict = lkif.get_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True False False False False False]\n",
      " [ True  True False False False  True]\n",
      " [False  True  True False False False]\n",
      " [False False False  True False False]\n",
      " [False False False  True  True False]\n",
      " [ True False False False  True  True]]\n"
     ]
    }
   ],
   "source": [
    "print(np.abs(result_dict[\"information_flow\"]) > result_dict[\"information_flow_std_origin\"] * 1.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9,  0. ,  0. , -0. , -0. , -0. ],\n",
       "       [ 0.6,  0.8,  0. , -0. , -0. , -0. ],\n",
       "       [ 0. ,  0.6,  0.9, -0. , -0. , -0. ],\n",
       "       [-0. , -0. , -0. ,  0.2,  0. ,  0. ],\n",
       "       [-0. , -0. , -0. ,  0.6,  0.2,  0. ],\n",
       "       [-0. , -0. , -0. ,  0. ,  0.6,  0.2]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([np.concatenate([A1,B1],axis=1),np.concatenate([B2,A2],axis=1)],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LKF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
